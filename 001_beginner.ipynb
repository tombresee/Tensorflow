{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001-beginner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tombresee/Tensorflow/blob/master/001_beginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# TensorFlow 2 quickstart for beginners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "04QgGZc9bF5D"
      },
      "source": [
        "This short introduction uses [Keras](https://www.tensorflow.org/guide/keras/overview) to:\n",
        "\n",
        "1. Build a neural network that classifies images.\n",
        "2. Train this neural network.\n",
        "3. And, finally, evaluate the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hiH7AC-NTniF"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "Download and install TensorFlow 2. Import TensorFlow into your program:\n",
        "\n",
        "Note: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0trJmd6DjqBZ",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Convert the samples from integers to floating-point numbers:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXLdsRV38wlS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjzA7EuL85dF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "9cc7e4cb-c97b-4e4c-9c2a-8ee267d7655c"
      },
      "source": [
        "\n",
        "\n",
        "dir(tf.keras)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Input',\n",
              " 'Model',\n",
              " 'Sequential',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " '_sys',\n",
              " 'activations',\n",
              " 'applications',\n",
              " 'backend',\n",
              " 'callbacks',\n",
              " 'constraints',\n",
              " 'datasets',\n",
              " 'estimator',\n",
              " 'experimental',\n",
              " 'initializers',\n",
              " 'layers',\n",
              " 'losses',\n",
              " 'metrics',\n",
              " 'mixed_precision',\n",
              " 'models',\n",
              " 'optimizers',\n",
              " 'preprocessing',\n",
              " 'regularizers',\n",
              " 'utils',\n",
              " 'wrappers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7FP5258xjs-v",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "# so it would be tf.keras.datasets.mnist.load_data() for longer version \n",
        "\n",
        "# This is a dataset of 60,000 28x28 grayscale images of the 10 digits, \n",
        "# along with a test set of 10,000 images. \n",
        "# More info can be found at the (MNIST homepage)[http://yann.lecun.com/exdb/mnist/].\n",
        "\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#  x_train, x_test: uint8 arrays of grayscale image data with shapes (num_samples, 28, 28).\n",
        "#  y_train, y_test: uint8 arrays of digit labels (integers in range 0-9) with shapes (num_samples,)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BPZ68wASog_I"
      },
      "source": [
        "Build the `tf.keras.Sequential` model by stacking layers. Choose an optimizer and loss function for training:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZbDQTse-Jo7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* tf.keras.Sequential model by stacking layers \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h3IKyzTCDNGo",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "tf.keras.layers.Dense(128, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmZ32AOxCFLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "632e1200-d91f-4304-f992-2d7799e1cf75"
      },
      "source": [
        "\n",
        "\n",
        "for method in dir(model):\n",
        "  if not method.startswith(\"_\"):\n",
        "    print(method)\n",
        "\n",
        "\n",
        "# activity_regularizer\n",
        "# add\n",
        "# add_loss\n",
        "# add_metric\n",
        "# add_update\n",
        "# add_variable\n",
        "# add_weight\n",
        "# apply\n",
        "# build\n",
        "# built\n",
        "# call\n",
        "# compile\n",
        "# compiled_loss\n",
        "# compiled_metrics\n",
        "# compute_mask\n",
        "# compute_output_shape\n",
        "# compute_output_signature\n",
        "# count_params\n",
        "# distribute_strategy\n",
        "# dtype\n",
        "# dynamic\n",
        "# evaluate\n",
        "# evaluate_generator\n",
        "# fit\n",
        "# fit_generator\n",
        "# from_config\n",
        "# get_config\n",
        "# get_input_at\n",
        "# get_input_mask_at\n",
        "# get_input_shape_at\n",
        "# get_layer\n",
        "# get_losses_for\n",
        "# get_output_at\n",
        "# get_output_mask_at\n",
        "# get_output_shape_at\n",
        "# get_updates_for\n",
        "# get_weights\n",
        "# history\n",
        "# inbound_nodes\n",
        "# input\n",
        "# input_mask\n",
        "# input_names\n",
        "# input_shape\n",
        "# input_spec\n",
        "# inputs\n",
        "# layers\n",
        "# load_weights\n",
        "# loss\n",
        "# losses\n",
        "# make_predict_function\n",
        "# make_test_function\n",
        "# make_train_function\n",
        "# metrics\n",
        "# metrics_names\n",
        "# name\n",
        "# name_scope\n",
        "# non_trainable_variables\n",
        "# non_trainable_weights\n",
        "# optimizer\n",
        "# outbound_nodes\n",
        "# output\n",
        "# output_mask\n",
        "# output_names\n",
        "# output_shape\n",
        "# outputs\n",
        "# pop\n",
        "# predict\n",
        "# predict_classes\n",
        "# predict_function\n",
        "# predict_generator\n",
        "# predict_on_batch\n",
        "# predict_proba\n",
        "# predict_step\n",
        "# reset_metrics\n",
        "# reset_states\n",
        "# run_eagerly\n",
        "# save\n",
        "# save_weights\n",
        "# set_weights\n",
        "# state_updates\n",
        "# stateful\n",
        "# stop_training\n",
        "# submodules\n",
        "# summary\n",
        "# supports_masking\n",
        "# test_function\n",
        "# test_on_batch\n",
        "# test_step\n",
        "# to_json\n",
        "# to_yaml\n",
        "# train_function\n",
        "# train_on_batch\n",
        "# train_step\n",
        "# trainable\n",
        "# trainable_variables\n",
        "# trainable_weights\n",
        "# updates\n",
        "# variables\n",
        "# weights\n",
        "# with_name_scope\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "activity_regularizer\n",
            "add\n",
            "add_loss\n",
            "add_metric\n",
            "add_update\n",
            "add_variable\n",
            "add_weight\n",
            "apply\n",
            "build\n",
            "built\n",
            "call\n",
            "compile\n",
            "compiled_loss\n",
            "compiled_metrics\n",
            "compute_mask\n",
            "compute_output_shape\n",
            "compute_output_signature\n",
            "count_params\n",
            "distribute_strategy\n",
            "dtype\n",
            "dynamic\n",
            "evaluate\n",
            "evaluate_generator\n",
            "fit\n",
            "fit_generator\n",
            "from_config\n",
            "get_config\n",
            "get_input_at\n",
            "get_input_mask_at\n",
            "get_input_shape_at\n",
            "get_layer\n",
            "get_losses_for\n",
            "get_output_at\n",
            "get_output_mask_at\n",
            "get_output_shape_at\n",
            "get_updates_for\n",
            "get_weights\n",
            "history\n",
            "inbound_nodes\n",
            "input\n",
            "input_mask\n",
            "input_names\n",
            "input_shape\n",
            "input_spec\n",
            "inputs\n",
            "layers\n",
            "load_weights\n",
            "loss\n",
            "losses\n",
            "make_predict_function\n",
            "make_test_function\n",
            "make_train_function\n",
            "metrics\n",
            "metrics_names\n",
            "name\n",
            "name_scope\n",
            "non_trainable_variables\n",
            "non_trainable_weights\n",
            "optimizer\n",
            "outbound_nodes\n",
            "output\n",
            "output_mask\n",
            "output_names\n",
            "output_shape\n",
            "outputs\n",
            "pop\n",
            "predict\n",
            "predict_classes\n",
            "predict_function\n",
            "predict_generator\n",
            "predict_on_batch\n",
            "predict_proba\n",
            "predict_step\n",
            "reset_metrics\n",
            "reset_states\n",
            "run_eagerly\n",
            "save\n",
            "save_weights\n",
            "set_weights\n",
            "state_updates\n",
            "stateful\n",
            "stop_training\n",
            "submodules\n",
            "summary\n",
            "supports_masking\n",
            "test_function\n",
            "test_on_batch\n",
            "test_step\n",
            "to_json\n",
            "to_yaml\n",
            "train_function\n",
            "train_on_batch\n",
            "train_step\n",
            "trainable\n",
            "trainable_variables\n",
            "trainable_weights\n",
            "updates\n",
            "variables\n",
            "weights\n",
            "with_name_scope\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxzh5g4uCTWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l2hiez2eIUz8"
      },
      "source": [
        "For each example the model returns a vector of \"[logits](https://developers.google.com/machine-learning/glossary#logits)\" or \"[log-odds](https://developers.google.com/machine-learning/glossary#log-odds)\" scores, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OeOrNdnkEEcR",
        "colab": {}
      },
      "source": [
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PeWFlLP3CeZm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "732078a7-9a64-41ea-80ef-1523399b8df2"
      },
      "source": [
        "\n",
        "predictions = model(x_train[:3]).numpy()\n",
        "predictions\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-12.299428  ,  -6.130061  ,  -4.803863  ,   7.121154  ,\n",
              "        -25.37767   ,  14.098568  , -11.531853  ,  -7.9039416 ,\n",
              "         -9.089745  ,  -3.1913404 ],\n",
              "       [ 11.184452  , -10.538819  ,   1.0759465 ,  -5.4458976 ,\n",
              "        -11.650076  ,  -0.647331  ,  -1.8918667 ,  -4.7918267 ,\n",
              "         -4.7937274 ,  -0.47624698],\n",
              "       [-11.481037  ,  -1.7591531 ,  -2.0422864 ,  -3.0177345 ,\n",
              "          7.6207933 ,  -6.2916703 ,  -5.231231  ,  -0.7957595 ,\n",
              "         -1.1651108 ,   0.581959  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5brgvom8DjrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df7975d6-ed48-4454-8841-09f4ba6bad72"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVcldGdACiEv",
        "colab_type": "text"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tgjhDQGcIniO"
      },
      "source": [
        "The `tf.nn.softmax` function converts these logits to \"probabilities\" for each class: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPmjBK1DDnyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "d9036105-a085-48b5-d428-63c66c86a944"
      },
      "source": [
        "help(tf.nn.softmax)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function softmax_v2 in module tensorflow.python.ops.nn_ops:\n",
            "\n",
            "softmax_v2(logits, axis=None, name=None)\n",
            "    Computes softmax activations.\n",
            "    \n",
            "    This function performs the equivalent of\n",
            "    \n",
            "        softmax = tf.exp(logits) / tf.reduce_sum(tf.exp(logits), axis)\n",
            "    \n",
            "    Args:\n",
            "      logits: A non-empty `Tensor`. Must be one of the following types: `half`,\n",
            "        `float32`, `float64`.\n",
            "      axis: The dimension softmax would be performed on. The default is -1 which\n",
            "        indicates the last dimension.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor`. Has the same type and shape as `logits`.\n",
            "    \n",
            "    Raises:\n",
            "      InvalidArgumentError: if `logits` is empty or `axis` is beyond the last\n",
            "        dimension of `logits`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zWSRnQ0WI5eq",
        "colab": {}
      },
      "source": [
        "tf.nn.softmax(predictions).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr8xLrucCqb-",
        "colab_type": "text"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "he5u_okAYS4a"
      },
      "source": [
        "Note: It is possible to bake this `tf.nn.softmax` in as the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to\n",
        "provide an exact and numerically stable loss calculation for all models when using a softmax output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hQyugpgRIyrA"
      },
      "source": [
        "The `losses.SparseCategoricalCrossentropy` loss takes a vector of logits and a `True` index and returns a scalar loss for each example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgvONOGUFCLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "0c79e413-0b99-411b-d9e3-de407cba3379"
      },
      "source": [
        "help(tf.keras)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package tensorflow.keras in tensorflow:\n",
            "\n",
            "NAME\n",
            "    tensorflow.keras - Implementation of the Keras API meant to be a high-level API for TensorFlow.\n",
            "\n",
            "DESCRIPTION\n",
            "    Detailed documentation and user guides are available at\n",
            "    [tensorflow.org](https://www.tensorflow.org/guide/keras).\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    activations (package)\n",
            "    applications (package)\n",
            "    backend (package)\n",
            "    callbacks (package)\n",
            "    constraints (package)\n",
            "    datasets (package)\n",
            "    estimator (package)\n",
            "    experimental (package)\n",
            "    initializers (package)\n",
            "    layers (package)\n",
            "    losses (package)\n",
            "    metrics (package)\n",
            "    mixed_precision (package)\n",
            "    models (package)\n",
            "    optimizers (package)\n",
            "    premade (package)\n",
            "    preprocessing (package)\n",
            "    regularizers (package)\n",
            "    utils (package)\n",
            "    wrappers (package)\n",
            "\n",
            "VERSION\n",
            "    2.3.0-tf\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/keras/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD-NQBBlFy_F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "847f625e-6bcc-4d58-e01d-2a2de4a9efba"
      },
      "source": [
        "\n",
        "# built in loss function\n",
        "\n",
        "help(tf.keras.losses.SparseCategoricalCrossentropy)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class SparseCategoricalCrossentropy in module tensorflow.python.keras.losses:\n",
            "\n",
            "class SparseCategoricalCrossentropy(LossFunctionWrapper)\n",
            " |  Computes the crossentropy loss between the labels and predictions.\n",
            " |  \n",
            " |  Use this crossentropy loss function when there are two or more label classes.\n",
            " |  We expect labels to be provided as integers. If you want to provide labels\n",
            " |  using `one-hot` representation, please use `CategoricalCrossentropy` loss.\n",
            " |  There should be `# classes` floating point values per feature for `y_pred`\n",
            " |  and a single floating point value per feature for `y_true`.\n",
            " |  \n",
            " |  In the snippet below, there is a single floating point value per example for\n",
            " |  `y_true` and `# classes` floating pointing values per example for `y_pred`.\n",
            " |  The shape of `y_true` is `[batch_size]` and the shape of `y_pred` is\n",
            " |  `[batch_size, num_classes]`.\n",
            " |  \n",
            " |  Usage:\n",
            " |  \n",
            " |  >>> y_true = [1, 2]\n",
            " |  >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            " |  >>> # Using 'auto'/'sum_over_batch_size' reduction type.\n",
            " |  >>> scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
            " |  >>> scce(y_true, y_pred).numpy()\n",
            " |  1.177\n",
            " |  \n",
            " |  >>> # Calling with 'sample_weight'.\n",
            " |  >>> scce(y_true, y_pred, sample_weight=tf.constant([0.3, 0.7])).numpy()\n",
            " |  0.814\n",
            " |  \n",
            " |  >>> # Using 'sum' reduction type.\n",
            " |  >>> scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
            " |  ...     reduction=tf.keras.losses.Reduction.SUM)\n",
            " |  >>> scce(y_true, y_pred).numpy()\n",
            " |  2.354\n",
            " |  \n",
            " |  >>> # Using 'none' reduction type.\n",
            " |  >>> scce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
            " |  ...     reduction=tf.keras.losses.Reduction.NONE)\n",
            " |  >>> scce(y_true, y_pred).numpy()\n",
            " |  array([0.0513, 2.303], dtype=float32)\n",
            " |  \n",
            " |  Usage with the `compile` API:\n",
            " |  \n",
            " |  ```python\n",
            " |  model = tf.keras.Model(inputs, outputs)\n",
            " |  model.compile('sgd', loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
            " |  ```\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      SparseCategoricalCrossentropy\n",
            " |      LossFunctionWrapper\n",
            " |      Loss\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, from_logits=False, reduction='auto', name='sparse_categorical_crossentropy')\n",
            " |      Initializes `SparseCategoricalCrossentropy` instance.\n",
            " |      \n",
            " |      Args:\n",
            " |        from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            " |          default, we assume that `y_pred` encodes a probability distribution.\n",
            " |          **Note - Using from_logits=True may be more numerically stable.\n",
            " |        reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to\n",
            " |          loss. Default value is `AUTO`. `AUTO` indicates that the reduction\n",
            " |          option will be determined by the usage context. For almost all cases\n",
            " |          this defaults to `SUM_OVER_BATCH_SIZE`. When used with\n",
            " |          `tf.distribute.Strategy`, outside of built-in training loops such as\n",
            " |          `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE`\n",
            " |          will raise an error. Please see this custom training [tutorial]\n",
            " |          (https://www.tensorflow.org/tutorials/distribute/custom_training)\n",
            " |          for more details.\n",
            " |        name: Optional name for the op. Defaults to\n",
            " |          'sparse_categorical_crossentropy'.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from LossFunctionWrapper:\n",
            " |  \n",
            " |  call(self, y_true, y_pred)\n",
            " |      Invokes the `LossFunctionWrapper` instance.\n",
            " |      \n",
            " |      Args:\n",
            " |        y_true: Ground truth values.\n",
            " |        y_pred: The predicted values.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Loss values per sample.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config dictionary for a `Loss` instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from Loss:\n",
            " |  \n",
            " |  __call__(self, y_true, y_pred, sample_weight=None)\n",
            " |      Invokes the `Loss` instance.\n",
            " |      \n",
            " |      Args:\n",
            " |        y_true: Ground truth values. shape = `[batch_size, d0, .. dN]`, except\n",
            " |          sparse loss functions such as sparse categorical crossentropy where\n",
            " |          shape = `[batch_size, d0, .. dN-1]`\n",
            " |        y_pred: The predicted values. shape = `[batch_size, d0, .. dN]`\n",
            " |        sample_weight: Optional `sample_weight` acts as a\n",
            " |          coefficient for the loss. If a scalar is provided, then the loss is\n",
            " |          simply scaled by the given value. If `sample_weight` is a tensor of size\n",
            " |          `[batch_size]`, then the total loss for each sample of the batch is\n",
            " |          rescaled by the corresponding element in the `sample_weight` vector. If\n",
            " |          the shape of `sample_weight` is `[batch_size, d0, .. dN-1]` (or can be\n",
            " |          broadcasted to this shape), then each loss element of `y_pred` is scaled\n",
            " |          by the corresponding value of `sample_weight`. (Note on`dN-1`: all loss\n",
            " |          functions reduce by 1 dimension, usually axis=-1.)\n",
            " |      \n",
            " |      Returns:\n",
            " |        Weighted loss float `Tensor`. If `reduction` is `NONE`, this has\n",
            " |          shape `[batch_size, d0, .. dN-1]`; otherwise, it is scalar. (Note `dN-1`\n",
            " |          because all loss functions reduce by 1 dimension, usually axis=-1.)\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the shape of `sample_weight` is invalid.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from Loss:\n",
            " |  \n",
            " |  from_config(config) from builtins.type\n",
            " |      Instantiates a `Loss` from its config (output of `get_config()`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: Output of `get_config()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `Loss` instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from Loss:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSkzdv8MD0tT",
        "colab": {}
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfR4MsSDU880"
      },
      "source": [
        "This loss is equal to the negative log probability of the true class:\n",
        "It is zero if the model is sure of the correct class.\n",
        "\n",
        "This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to `-tf.log(1/10) ~= 2.3`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NJWqEVrrJ7ZB",
        "colab": {}
      },
      "source": [
        "loss_fn(y_train[:1], predictions).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9foNKHzTD2Vo",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(optimizer='adam',\n",
        "              \n",
        "              loss=loss_fn,\n",
        "              \n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ix4mEL65on-w"
      },
      "source": [
        "The `Model.fit` method adjusts the model parameters to minimize the loss: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y7suUbJXVLqP",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4mDAAPFqVVgn"
      },
      "source": [
        "The `Model.evaluate` method checks the models performance, usually on a \"[Validation-set](https://developers.google.com/machine-learning/glossary#validation-set)\" or \"[Test-set](https://developers.google.com/machine-learning/glossary#test-set)\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWVC6-D_C2HE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8058ea3a-0b87-495d-d5e7-feba8da30e5a"
      },
      "source": [
        "help(model.evaluate)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method evaluate in module tensorflow.python.keras.engine.training:\n",
            "\n",
            "evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False) method of tensorflow.python.keras.engine.sequential.Sequential instance\n",
            "    Returns the loss value & metrics values for the model in test mode.\n",
            "    \n",
            "    Computation is done in batches.\n",
            "    \n",
            "    Arguments:\n",
            "        x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            "          of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            "          tensor, or a list of tensors (in case the model has multiple inputs).\n",
            "          - A dict mapping input names to the corresponding array/tensors, if\n",
            "          the model has named inputs. - A `tf.data` dataset. - A generator or\n",
            "          `keras.utils.Sequence` instance. A more detailed description of\n",
            "          unpacking behavior for iterator types (Dataset, generator, Sequence)\n",
            "          is given in the `Unpacking behavior for iterator-like inputs` section\n",
            "          of `Model.fit`.\n",
            "        y: Target data. Like the input data `x`, it could be either Numpy\n",
            "          array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            "          (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            "          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            "          should not be specified (since targets will be obtained from the\n",
            "          iterator/dataset).\n",
            "        batch_size: Integer or `None`. Number of samples per gradient update. If\n",
            "          unspecified, `batch_size` will default to 32. Do not specify the\n",
            "          `batch_size` if your data is in the form of a dataset, generators,\n",
            "          or `keras.utils.Sequence` instances (since they generate batches).\n",
            "        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
            "        sample_weight: Optional Numpy array of weights for the test samples,\n",
            "          used for weighting the loss function. You can either pass a flat (1D)\n",
            "          Numpy array with the same length as the input samples\n",
            "            (1:1 mapping between weights and samples), or in the case of\n",
            "              temporal data, you can pass a 2D array with shape `(samples,\n",
            "              sequence_length)`, to apply a different weight to every timestep\n",
            "              of every sample. In this case you should make sure to specify\n",
            "              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is\n",
            "              not supported when `x` is a dataset, instead pass sample weights\n",
            "              as the third element of `x`.\n",
            "        steps: Integer or `None`. Total number of steps (batches of samples)\n",
            "          before declaring the evaluation round finished. Ignored with the\n",
            "          default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            "          None, 'evaluate' will run until the dataset is exhausted. This\n",
            "          argument is not supported with array inputs.\n",
            "        callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            "          callbacks to apply during evaluation. See\n",
            "          [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            "          input only. Maximum size for the generator queue. If unspecified,\n",
            "          `max_queue_size` will default to 10.\n",
            "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            "          only. Maximum number of processes to spin up when using process-based\n",
            "          threading. If unspecified, `workers` will default to 1. If 0, will\n",
            "          execute the generator on the main thread.\n",
            "        use_multiprocessing: Boolean. Used for generator or\n",
            "          `keras.utils.Sequence` input only. If `True`, use process-based\n",
            "          threading. If unspecified, `use_multiprocessing` will default to\n",
            "          `False`. Note that because this implementation relies on\n",
            "          multiprocessing, you should not pass non-picklable arguments to the\n",
            "          generator as they can't be passed easily to children processes.\n",
            "        return_dict: If `True`, loss and metric results are returned as a dict,\n",
            "          with each key being the name of the metric. If `False`, they are\n",
            "          returned as a list.\n",
            "    \n",
            "    See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            "    `Model.fit`.\n",
            "    \n",
            "    Returns:\n",
            "        Scalar test loss (if the model has a single output and no metrics)\n",
            "        or list of scalars (if the model has multiple outputs\n",
            "        and/or metrics). The attribute `model.metrics_names` will give you\n",
            "        the display labels for the scalar outputs.\n",
            "    \n",
            "    Raises:\n",
            "        ValueError: in case of invalid arguments.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1OBJ-tRGnBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ae4c42f-2be3-431e-9714-541b9719bb90"
      },
      "source": [
        "\n",
        "\n",
        "help(model.evaluate)\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method evaluate in module tensorflow.python.keras.engine.training:\n",
            "\n",
            "evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False) method of tensorflow.python.keras.engine.sequential.Sequential instance\n",
            "    Returns the loss value & metrics values for the model in test mode.\n",
            "    \n",
            "    Computation is done in batches.\n",
            "    \n",
            "    Arguments:\n",
            "        x: Input data. It could be: - A Numpy array (or array-like), or a list\n",
            "          of arrays (in case the model has multiple inputs). - A TensorFlow\n",
            "          tensor, or a list of tensors (in case the model has multiple inputs).\n",
            "          - A dict mapping input names to the corresponding array/tensors, if\n",
            "          the model has named inputs. - A `tf.data` dataset. - A generator or\n",
            "          `keras.utils.Sequence` instance. A more detailed description of\n",
            "          unpacking behavior for iterator types (Dataset, generator, Sequence)\n",
            "          is given in the `Unpacking behavior for iterator-like inputs` section\n",
            "          of `Model.fit`.\n",
            "        y: Target data. Like the input data `x`, it could be either Numpy\n",
            "          array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            "          (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            "          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            "          should not be specified (since targets will be obtained from the\n",
            "          iterator/dataset).\n",
            "        batch_size: Integer or `None`. Number of samples per gradient update. If\n",
            "          unspecified, `batch_size` will default to 32. Do not specify the\n",
            "          `batch_size` if your data is in the form of a dataset, generators,\n",
            "          or `keras.utils.Sequence` instances (since they generate batches).\n",
            "        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
            "        sample_weight: Optional Numpy array of weights for the test samples,\n",
            "          used for weighting the loss function. You can either pass a flat (1D)\n",
            "          Numpy array with the same length as the input samples\n",
            "            (1:1 mapping between weights and samples), or in the case of\n",
            "              temporal data, you can pass a 2D array with shape `(samples,\n",
            "              sequence_length)`, to apply a different weight to every timestep\n",
            "              of every sample. In this case you should make sure to specify\n",
            "              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is\n",
            "              not supported when `x` is a dataset, instead pass sample weights\n",
            "              as the third element of `x`.\n",
            "        steps: Integer or `None`. Total number of steps (batches of samples)\n",
            "          before declaring the evaluation round finished. Ignored with the\n",
            "          default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            "          None, 'evaluate' will run until the dataset is exhausted. This\n",
            "          argument is not supported with array inputs.\n",
            "        callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            "          callbacks to apply during evaluation. See\n",
            "          [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            "          input only. Maximum size for the generator queue. If unspecified,\n",
            "          `max_queue_size` will default to 10.\n",
            "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            "          only. Maximum number of processes to spin up when using process-based\n",
            "          threading. If unspecified, `workers` will default to 1. If 0, will\n",
            "          execute the generator on the main thread.\n",
            "        use_multiprocessing: Boolean. Used for generator or\n",
            "          `keras.utils.Sequence` input only. If `True`, use process-based\n",
            "          threading. If unspecified, `use_multiprocessing` will default to\n",
            "          `False`. Note that because this implementation relies on\n",
            "          multiprocessing, you should not pass non-picklable arguments to the\n",
            "          generator as they can't be passed easily to children processes.\n",
            "        return_dict: If `True`, loss and metric results are returned as a dict,\n",
            "          with each key being the name of the metric. If `False`, they are\n",
            "          returned as a list.\n",
            "    \n",
            "    See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            "    `Model.fit`.\n",
            "    \n",
            "    Returns:\n",
            "        Scalar test loss (if the model has a single output and no metrics)\n",
            "        or list of scalars (if the model has multiple outputs\n",
            "        and/or metrics). The attribute `model.metrics_names` will give you\n",
            "        the display labels for the scalar outputs.\n",
            "    \n",
            "    Raises:\n",
            "        ValueError: in case of invalid arguments.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F7dTAzgHDUh7",
        "colab": {}
      },
      "source": [
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)\n",
        "# model.evaluate(x_test)\n",
        "# loss value and metrics value\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Aj8NrlzlJqDG"
      },
      "source": [
        "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rYb6DrEH0GMv",
        "colab": {}
      },
      "source": [
        "probability_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.Softmax()\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cnqOZtUp1YR_",
        "colab": {}
      },
      "source": [
        "probability_model(x_test[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcNNklijDQSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#  tf.keras.Sequential([model,    \n",
        "#     tf.keras.layers.Softmax()  ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}